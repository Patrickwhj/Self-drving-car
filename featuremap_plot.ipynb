{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "[[1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"MIT License\n",
    "\n",
    "Copyright (c) 2019 Philippe Rémy\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n",
    "© 2019 GitHub, Inc.\"\"\"\n",
    "\n",
    "%matplotlib inline\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from PIL import Image\n",
    "import glob\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import dataset_load\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from keras.models import load_model\n",
    "\n",
    "def get_activations(model, x, layer_name=None):\n",
    "    \"\"\"\n",
    "    Get output activations for all filters for each layer\n",
    "    :param model: keras compiled model \n",
    "    :param x: input for which activations are sought (can be a batch input)\n",
    "    :param layer_name: if activations of a particular layer are sought\n",
    "    :return: dict mapping layers to corresponding activations (batch_size, output_h, output_w, num_filters)\n",
    "    \"\"\"\n",
    "    nodes = [layer.output for layer in model.layers if layer.name == layer_name or layer_name is None]\n",
    "    # we process the placeholders later (Inputs node in Keras). Because there's a bug in Tensorflow.\n",
    "    input_layer_outputs, layer_outputs = [], []\n",
    "    [input_layer_outputs.append(node) if 'input_' in node.name else layer_outputs.append(node) for node in nodes]\n",
    "    activations = _evaluate(model, layer_outputs, x, y=None)\n",
    "    activations_dict = dict(zip([output.name for output in layer_outputs], activations))\n",
    "    activations_inputs_dict = dict(zip([output.name for output in input_layer_outputs], x))\n",
    "    result = activations_inputs_dict.copy()\n",
    "    result.update(activations_dict)\n",
    "    return result\n",
    "\n",
    "def display_activations(activations, cmap='gray', save=False):\n",
    "    \"\"\"\n",
    "    Plot heatmaps of activations for all filters for each layer\n",
    "    :param activations: dict mapping layers to corresponding activations (1, output_h, output_w, num_filters)\n",
    "    :param cmap: string - a valid matplotlib colourmap to be used\n",
    "    :param save: bool- if the plot should be saved\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import math\n",
    "    for layer_name, acts in activations.items():\n",
    "        #print(layer_name, acts.shape, end='')\n",
    "        if acts.shape[0] != 1:\n",
    "            print('-> Skipped. First dimension is not 1.')\n",
    "            continue\n",
    "        if len(acts.shape) <= 2:\n",
    "            print('-> Skipped. 2D Activations.')\n",
    "            continue\n",
    "        print('')\n",
    "        nrows = int(math.sqrt(acts.shape[-1]) - 0.001) + 1  # best square fit for the given number\n",
    "        ncols = int(math.ceil(acts.shape[-1] / nrows))\n",
    "        fig, axes = plt.subplots(nrows, ncols, figsize=(12, 12))\n",
    "        fig.suptitle(layer_name)\n",
    "        for i in range(nrows * ncols):\n",
    "            if i < acts.shape[-1]:\n",
    "                img = acts[0, :, :, i]\n",
    "                hmap = axes.flat[i].imshow(img, cmap=cmap)\n",
    "            axes.flat[i].axis('off')\n",
    "        fig.subplots_adjust(right=0.8)\n",
    "        cbar = fig.add_axes([0.85, 0.15, 0.03, 0.7])\n",
    "        fig.colorbar(hmap, cax=cbar)\n",
    "        if save:\n",
    "            plt.savefig(layer_name.split('/')[0] + '.png', bbox_inches='tight')\n",
    "        else:\n",
    "            plt.show()\n",
    "        # pyplot figures require manual closing\n",
    "        plt.close(fig)\n",
    "\n",
    "def _evaluate(model, nodes_to_evaluate, x, y=None):\n",
    "    if not model._is_compiled:\n",
    "        if model.name in ['vgg16', 'vgg19', 'inception_v3', 'inception_resnet_v2', 'mobilenet_v2', 'mobilenetv2']:\n",
    "            print('Transfer learning detected. Model will be compiled with (\"categorical_crossentropy\", \"adam\").')\n",
    "            print('If you want to change the default behaviour, then do in python:')\n",
    "            print('model.name = \"\"')\n",
    "            print('Then compile your model with whatever loss you want: https://keras.io/models/model/#compile.')\n",
    "            print('If you want to get rid of this message, add this line before calling keract:')\n",
    "            print('model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")')\n",
    "            model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        else:\n",
    "            print('Please compile your model first! https://keras.io/models/model/#compile.')\n",
    "            print('If you only care about the activations (outputs of the layers), '\n",
    "                  'then just compile your model like that:')\n",
    "            print('model.compile(loss=\"mse\", optimizer=\"adam\")')\n",
    "            raise Exception('Compilation of the model required.')\n",
    "    symb_inputs = (model._feed_inputs + model._feed_targets + model._feed_sample_weights)\n",
    "    f = K.function(symb_inputs, nodes_to_evaluate)\n",
    "    x_, y_, sample_weight_ = model._standardize_user_data(x, y)\n",
    "    return f(x_ + y_ + sample_weight_)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    image = Image.open('./2.jpg')# Image path\n",
    "    image = np.array(image)\n",
    "    image= np.expand_dims(image, axis=0)\n",
    "    model=load_model(\"model-001.h5\")# Model path\n",
    "    display_activations(get_activations(model, image)) \n",
    "    #print(model.predict(image))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
